// Operating System and its function:
    Operating system provides an interface b/w hardware and users/software
   // Functionalities:
        : Resource management(hardware)
        : Process management(Cpu)
        : Storage management(HardDisk)
        : Memory management(RAM)

// Idle: when cpu has no task to execute
// Multiprogrammed: (We try to put more no of task in RAM) (try to reduce idelness)
                    : Non preemptive(Switch occurs b/w to process if only running process allows)
// Multitasking: (We try to run more no of process)(time sharing) (try to reduce response time)
                : preemptive(Switch occurs b/w two process continueously for fixed time/ or due to priority)

// Process states: New/Create -> Ready -> Running -> Terminated
                                   Running -> Wait/Block -> Ready
                                   Running -> Ready
                                   Ready <-> Suspend ready(Secondary memory)
                                   Wait <-> Suspend Wait (Secondary memory)

// Long term schedular: It puts more no of processes in ready state from new state(Multiprogramming)
// Short term schedular: It puts processes from ready state to running state.
// Medium short schedular: If RAM is full due to ready queue or waiting queue then the processes has to put in Secondary memory called suspend state by Medium term schedular.

// chmod command: three categories: user(read(4),write(2),execute(1))+group(read,write,execute)+other(read,write,execute)
// lseak command: To move read write head 
                eg) lseak(file_descriptor,#,SEEK_CUR) // change head # number ahead from current position
                    lseak(file_descriptor,#,SEEK_SET) // set head position to # position.

// System Calls:
    By the help of system call we can use kernal mode Functionalities or we can switch from user to kernal mode.
// Fork(): 
    : It creates exactly clone of the parent process which has own process id.
    : return value : 0 for child and +ve for parent
    : no of child = pow(2,no of fork())-1.

// User mode vs Kernal mode:
    : When a process is running in user mode and if it call a system call then a trap generates and process shift from user mode to
      kernal mode (mode bit change from 1 to 0) then system calls get executed and process return from system call (mode 0 to 1) trap release.

// process vs threads: 
    : System calls involves in process but not in threads.
    : OS treats different processes differently but all user level threads treated as single task for OS.
    : different process have different copies of data, files, code but threads share same copy of code and data(but have different stacks and registers).
    : Context switching in slower in processes but faster in threads.
    : Blocking a process will not blocks another but Blocking a thread blocks entire process.
    : processes are independent but threads are interdependent.

// User level vs kernal level thread:
    : User level thread are managed by user level library but kernal level threads managed by OS.
    : user level threads are typicallu fast but kernal level threads are slow.
    : Context switching(process) > Context switching(kernal level threads) > Context switching(user level threads).
    : If one user level thread perform blocking operation then entire process get blocked but if one kernal level thread blocke, it not affect others.

// Scheduling algorithms:
    : It is a way to put processes to cpu from ready queue.
    : Pre- Emptive and Non Pre-Emptive

// Arrival time: The time at which a process enter the Ready queue.
// Burst time: Time required by a process to execute on cpu.
// Completion time: The time at which a process completes its execution.
// Turn around time: Completion time - Arrival time.
// Waiting time: Turn around time - Burst time.
// Response time: Time at which a process got cpu for first time - Arrival time.

// FCFS(First come first serve) Scheduling algorithm: Criteria- Arrival time and mode - non preemptive 
// SJF(Sortest Job First) Scheduling algorithm: Criteria- Burst time and mode - non preemptive 
// SRTF(Sortest Remaining time First)(SJF+preemption) Scheduling algorithm: Criteria- Remaining time and mode - preemptive 
// RR(Round Robin) Scheduling algorithm: Criteria- Time quantum and mode - preemptive : It contain one ready queue for sequence of processes.
                                                                                        After each time quantum put the running process in ready queue
                                                                                        and select a process present at front of ready queue(Context switching).
                                                                                    
// Multilevel queue Scheduling: We categorised different processes according to their priority and make different ready queue for that processes.
                                : All ready queue can have different Scheduling algorithms.
                                : problem - starvation

// Multilevel Feedback queue:
    :This method is used for lower priority process in Multilevel queue Scheduling.
    :First processes comes in their respective ready queue and after fix amount of time of their execution in that queue,
    they shift to next high priority queue.

// Process Syncronization:
    // There are two types of process:
        : Co-operative: They share variable, code, memory, resources, etc.(Execution of one process affect the other)
        : Indepedent 
    // If we not syncronize the co-operative processes then race condition(some processes race for their execution without any Syncronization) can occurs .

// Critical Section: It is part of the program where shared recources are accessed by various processes.
                    : We add entry and exit section code/rules for Critical section to prevent the race condition.

// We have to follow 4 rules/ condition fo Syncronization mechanism for acheiving Syncronization:
    Primary:
    : Mutual Exclution(Only one process can enter into Critical section at one time)
    : Progress(No process will prevent the use of critical section by another process when itself process is not using critical section)
    Secondary:
    : Bounded wait(One process cannot use critical section infinite no of times result to starvation of another processes)
    : No assumtion related to hardware/speed(portable).

// Lock: A process aquire lock when its uses critical section and release when the work is complete 
    : value 1 for lock is aquired/full and 0 for vacant
    // Execute in user mode.
    // Multiprocess solution.
    // No Mutual Exclution guarantee.
    eg) while(lock==1);
        lock=1;
        // critical section
        lock=0;

// Test and Set: It work on same method as lock but it made first two line of lock atomic 
                It test ans set the lock varibale in one line my a method.
                eg) while(test_and_set(& lock));
                    // critical section
                    lock=flase;

                    test_and_set(bool *target){
                        bool r=*target;
                        target=true;
                        return r;
                    }
                : Mutual Exclution acheived.
                : Progress acheived.

// Turn variable: 2 process solution for critical section Syncronization.
                : Run in user mode
                eg)  for process 1            for process 2
                    while(turn != 0);       while(turn != 1);
                    // critical section     // critical section
                    turn = 1;               turn = 0;
                : Mutual Exclution acheived.
                : Progress not acheived.
                : Bounded wait acheived.
            
// Semaphores: Semaphores is a integer variable which is used in Mutual exclusive manner by various concurrent co-operative processes in order to achieve Syncronization.
            : We use to types of integer range: 
                :Counting(-inf to +inf)
                :Binary(0,1)
            : We use P() and V(), Down and Up, Wait and Signal where P(), Down and Wait are entry codes.
        eg) Down (Semaphore S){
                S.value=S.value-1;
                if(S.value<0){
                    Put process(PCB) in suspended list, 
                    sleep();
                }
                else{
                    retrun;
                }
            }
            Up(Semaphore S){
                S.value=S.value+1;
                if(S.value<=0){
                    Select a process from suspended list,
                    WakeUp();
                }
            }

// Solution of producer consumer problem using Semaphore:
    Empty=size;
    Full=0;
    binary Semaphore S=1;
    Produce(item p){
        down(Empty);
        down(S);
        Buffer[in]=p;
        in+=1;
        in%=size;
        up(S);
        up(Full);
    }
    Consume{
        down(Full);
        down(S);
        item p=Buffer[out];
        out+=1;
        out%=size;
        up(S);
        up(Empty);
    }

// Solution of reader-writer problem:
    int rc=0;
    Semaphore mutex=1,db=1;
    void reader(){
        while(true){
            down(mutex);
            rc+=1;
            if(rc==1) down(db);
            up(mutex);

            // Database access

            down(mutex);
            rc-=1;
            if(rc==0) then up(db);
            up(mutex);
            process data;
        }
    }
    void writer(){
        while(true){
            down(db);
            // Database access
            up(db);
        }
    }

// Dining philosophers problem:
    void(){
        while(true){
            thinking();
            down(fork_(S[i]));
            down(fork_(S[i+1]));
            Eat();
            up(fork_(S[i]));
            up(fork_(S[i+1]));
        }
    } // if all the philosophers takes the ith fork and wait for i+1th fork then the case will of deadlock;
    // we can remove deadlock by simply change the down condition for any philosopher to down i+1th fork first then ith fork

// Deadlock:
    If two or more process are waiting on happening of some event which never happens, then we say these processes are involved in deadlock,
    then that state is called deadlock.
// Neccessary conditions for deadlock:
    : Mutual exclusion
    : No preemption
    : Hold & Wait
    : Circular wait

// Recource allocation graph:
    : we draw an edge from a recource to a process if the recource has been taken by that process.
    : we draw an edge from a process to a recource if the process has demand for that recource.
    : If there is a single instance of all recources then cyclic wait denotes deadlock and acyclic wait denotes no deadlock.
    : If there is multiple instances of recources then we have to use an algorithm(Banker's) to check deadlock.
    : the algorithm(Banker's) is: 
        : draw a table that contains how many recources allocated to a process and how many they need.
        : then maintain a state that contain how may free recources are present if any process can execute by taking some available
        recource from that state then give the recource to that process and take all the recource which was held by that process.
        : try to execute all the processes by similar fashion 
        : if all the processes get execute then there is no deadlock o/w deadlock.

// Various methods for handling deadlocks:
    : Deadlock Ingnorance(Ostrich method): we cannot affect performance of the system due to handle rare deadlocks.
    : Deadlock prevention: Try to discard one of the Neccessary condition for deadlock.
    : Deadlock Avoidance (Banker's algorithm)
    : Deadlock detection & recovery 
    
// Deadlock Avoidance algorithm(Banker's algorithm):
    : draw a table that contains how many recources allocated to a process and how many they need.
    : then maintain a state that contain how may free recources are present if any process can execute by taking some available
    recource from that state then give the recource to that process and take all the recource which was held by that process.
    : try to execute all the processes by similar fashion 
    : if all the processes get execute then there is no deadlock o/w deadlock.

// Memory management system: Efficient utilization of memory.

// Degree of Multiprogramming: Try to keep more and more program on RAM such that the efficiency of the system can increase.

// Memory management technique:
    Contiguous:
        : Fixed partitioning
        : Varibale partioning
    Non Contiguous:
        : Paging
        : Multilevel Paging
        : Inverted Paging
        : Segmentation
        : Segmented paging

// Disadvantage of fixed programming:   
    : Internal fragmentation (If we cannot use some space(the left space after aquiring space by a process in a fixed block), then it called )
    : Limit in process size
    : Limitation in degree of Multiprogramming
    : External fragmentation (If the some of some small space is greater than a process still we cannot accommodate that process due to
                            Contiguous memory allocation then this situation is called External fragmentation).

// Advantages of dynamic/variable partitioning:
    : No Internal fragmentation
    : No Limitation on degree of Multiprogramming.
    : No Limitation on process size.
// Disadvantage:
    : External fragmentation still present(but we can use undesirable method called compaction).
    : Allocation and dellocation is little complex.

// Memory allocation in variable partitioning:
    : First Fit: Allocate the process where space is enough for the process starting from top.(Simple and fast)
    : Next Fit: Same as first fit but starts the allocation from last alllocated hole.
    : Best Fit: Allocate the smallest hole that is big enough.(Internal fragmentation less but slow)
    : Worst Fit: Allocate the largest hole.(slow)

// Paging: (no External fragmentation)
    : page: The processes are divided in small fixed size pieces(page), called paging.
    : Frame: We are divide the main memory into small fixed pieces called frames.
    // size of a frame = size of a page

// Page table: Memory management unit provides the page table which maps pages to frames .
            // every process has its own page table

// we have to find the actual address(physical address(frames+offset)) of a process in main memory from address produced by cpu for a process(logical address(page+offset)).

// size of a logical address = log2(logical address space)
// size of a physical address = log2(physical address space)
// logical address = (page number) + page offset(size = log2(page size))
// physical address = (frame number) + page offset
// number of pages = pow(2,page number size)
// number of frame = pow(2,frame number size)
// number of entry in a page table = number of pages.
// Size of page table = no of pages * log2(no of frames) = no of pages * frame number size // page table map page no to frame no

// Page table entry can consists:
    :Frame number bit
    :Valid/present bit
    :protection bit
    :reference bit
    :caching bit
    :dirty/modified bit

// Multilevel paging:If the size of page table bigger than size of a frame in main memory then we have to devide 
                     our page table into pages, this method is called Multilevel paging.

// Inverted paging:There is one page table for all the processes which consists frame no as index and page no + process id as page table entry
                : searching slow

// Thrashing: The cpu utilization increases with increasing degree of Multiprogramming but drops suddenly after a fixed value of degree of Multiprogramming
                and this drop in cpu utilization is called Thrashing.
            : prevent: by increase in RAM size
                     : by slowing long term schedular

// Segmentation: Unlike paging we devide a process into segments according to user point of view such that each segment has a specific meaning of related data(block of process)
                : We uses segment table for mapping the VA to PA that consists segment no as index and Base address + size (limit) as segment table entry.
                : VA = segment no + segment offset(offset<= limit) o/w error(trap/Segmentation fault)