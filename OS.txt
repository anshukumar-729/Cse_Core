** source: Youtube video by Gate Smasher **

// Operating System and its function:
    Operating system provides an interface b/w hardware and users/software
   // Functionalities:
        : Resource management(hardware)
        : Process management(Cpu)
        : Storage management(HardDisk)
        : Memory management(RAM)

// Idle: when cpu has no task to execute
// Multiprogrammed: (We try to put more no of task in RAM) (try to reduce idelness)
                    : Non preemptive(Switch occurs b/w to process if only running process allows)
// Multitasking: (We try to run more no of process)(time sharing) (try to reduce response time)
                : preemptive(Switch occurs b/w two process continueously for fixed time/ or due to priority)

// Process states: New/Create -> Ready -> Running -> Terminated
                                   Running -> Wait/Block -> Ready
                                   Running -> Ready
                                   Ready <-> Suspend ready(Secondary memory)
                                   Wait <-> Suspend Wait (Secondary memory)

// Long term schedular: It puts more no of processes in ready state from new state(Multiprogramming)
// Short term schedular: It puts processes from ready state to running state.
// Medium short schedular: If RAM is full due to ready queue or waiting queue then the processes has to put in Secondary memory called suspend state by Medium term schedular.

// chmod command: three categories: user(read(4),write(2),execute(1))+group(read,write,execute)+other(read,write,execute)
// lseak command: To move read write head 
                eg) lseak(file_descriptor,#,SEEK_CUR) // change head # number ahead from current position
                    lseak(file_descriptor,#,SEEK_SET) // set head position to # position.

// System Calls:
    By the help of system call we can use kernal mode Functionalities or we can switch from user to kernal mode.
// Fork(): 
    : It creates exactly clone of the parent process which has own process id.
    : return value : 0 for child and +ve for parent
    : no of child = pow(2,no of fork())-1.

// User mode vs Kernal mode:
    : When a process is running in user mode and if it call a system call then a trap generates and process shift from user mode to
      kernal mode (mode bit change from 1 to 0) then system calls get executed and process return from system call (mode 0 to 1) trap release.

// process vs threads: 
    : System calls involves in process but not in threads.
    : OS treats different processes differently but all user level threads treated as single task for OS.
    : different process have different copies of data, files, code but threads share same copy of code and data(but have different stacks and registers).
    : Context switching in slower in processes but faster in threads.
    : Blocking a process will not blocks another but Blocking a thread blocks entire process.
    : processes are independent but threads are interdependent.

// User level vs kernal level thread:
    : User level thread are managed by user level library but kernal level threads managed by OS.
    : user level threads are typicallu fast but kernal level threads are slow.
    : Context switching(process) > Context switching(kernal level threads) > Context switching(user level threads).
    : If one user level thread perform blocking operation then entire process get blocked but if one kernal level thread blocke, it not affect others.

// Scheduling algorithms:
    : It is a way to put processes to cpu from ready queue.
    : Pre- Emptive and Non Pre-Emptive

// Arrival time: The time at which a process enter the Ready queue.
// Burst time: Time required by a process to execute on cpu.
// Completion time: The time at which a process completes its execution.
// Turn around time: Completion time - Arrival time.
// Waiting time: Turn around time - Burst time.
// Response time: Time at which a process got cpu for first time - Arrival time.

// FCFS(First come first serve) Scheduling algorithm: Criteria- Arrival time and mode - non preemptive 
// SJF(Sortest Job First) Scheduling algorithm: Criteria- Burst time and mode - non preemptive 
// SRTF(Sortest Remaining time First)(SJF+preemption) Scheduling algorithm: Criteria- Remaining time and mode - preemptive 
// RR(Round Robin) Scheduling algorithm: Criteria- Time quantum and mode - preemptive : It contain one ready queue for sequence of processes.
                                                                                        After each time quantum put the running process in ready queue
                                                                                        and select a process present at front of ready queue(Context switching).
                                                                                    
// Multilevel queue Scheduling: We categorised different processes according to their priority and make different ready queue for that processes.
                                : All ready queue can have different Scheduling algorithms.
                                : problem - starvation

// Multilevel Feedback queue:
    :This method is used for lower priority process in Multilevel queue Scheduling.
    :First processes comes in their respective ready queue and after fix amount of time of their execution in that queue,
    they shift to next high priority queue.

// Process Syncronization:
    // There are two types of process:
        : Co-operative: They share variable, code, memory, resources, etc.(Execution of one process affect the other)
        : Indepedent 
    // If we not syncronize the co-operative processes then race condition(some processes race for their execution without any Syncronization) can occurs .

// Critical Section: It is part of the program where shared recources are accessed by various processes.
                    : We add entry and exit section code/rules for Critical section to prevent the race condition.

// We have to follow 4 rules/ condition fo Syncronization mechanism for acheiving Syncronization:
    Primary:
    : Mutual Exclution(Only one process can enter into Critical section at one time)
    : Progress(No process will prevent the use of critical section by another process when itself process is not using critical section)
    Secondary:
    : Bounded wait(One process cannot use critical section infinite no of times result to starvation of another processes)
    : No assumtion related to hardware/speed(portable).

// Lock: A process aquire lock when its uses critical section and release when the work is complete 
    : value 1 for lock is aquired/full and 0 for vacant
    // Execute in user mode.
    // Multiprocess solution.
    // No Mutual Exclution guarantee.
    eg) while(lock==1);
        lock=1;
        // critical section
        lock=0;

// Test and Set: It work on same method as lock but it made first two line of lock atomic 
                It test ans set the lock varibale in one line my a method.
                eg) while(test_and_set(& lock));
                    // critical section
                    lock=flase;

                    test_and_set(bool *target){
                        bool r=*target;
                        target=true;
                        return r;
                    }
                : Mutual Exclution acheived.
                : Progress acheived.

// Turn variable: 2 process solution for critical section Syncronization.
                : Run in user mode
                eg)  for process 1            for process 2
                    while(turn != 0);       while(turn != 1);
                    // critical section     // critical section
                    turn = 1;               turn = 0;
                : Mutual Exclution acheived.
                : Progress not acheived.
                : Bounded wait acheived.
            
// Semaphores: Semaphores is a integer variable which is used in Mutual exclusive manner by various concurrent co-operative processes in order to achieve Syncronization.
            : We use to types of integer range: 
                :Counting(-inf to +inf)
                :Binary(0,1)
            : We use P() and V(), Down and Up, Wait and Signal where P(), Down and Wait are entry codes.
        eg) Down (Semaphore S){
                S.value=S.value-1;
                if(S.value<0){
                    Put process(PCB) in suspended list, 
                    sleep();
                }
                else{
                    retrun;
                }
            }
            Up(Semaphore S){
                S.value=S.value+1;
                if(S.value<=0){
                    Select a process from suspended list,
                    WakeUp();
                }
            }

// Solution of producer consumer problem using Semaphore:
    Empty=size;
    Full=0;
    binary Semaphore S=1;
    Produce(item p){
        down(Empty);
        down(S);
        Buffer[in]=p;
        in+=1;
        in%=size;
        up(S);
        up(Full);
    }
    Consume{
        down(Full);
        down(S);
        item p=Buffer[out];
        out+=1;
        out%=size;
        up(S);
        up(Empty);
    }

// Solution of reader-writer problem:
    int rc=0;
    Semaphore mutex=1,db=1;
    void reader(){
        while(true){
            down(mutex);
            rc+=1;
            if(rc==1) down(db);
            up(mutex);

            // Database access

            down(mutex);
            rc-=1;
            if(rc==0) then up(db);
            up(mutex);
            process data;
        }
    }
    void writer(){
        while(true){
            down(db);
            // Database access
            up(db);
        }
    }

// Dining philosophers problem:
    void(){
        while(true){
            thinking();
            down(fork_(S[i]));
            down(fork_(S[i+1]));
            Eat();
            up(fork_(S[i]));
            up(fork_(S[i+1]));
        }
    } // if all the philosophers takes the ith fork and wait for i+1th fork then the case will of deadlock;
    // we can remove deadlock by simply change the down condition for any philosopher to down i+1th fork first then ith fork

// Deadlock:
    If two or more process are waiting on happening of some event which never happens, then we say these processes are involved in deadlock,
    then that state is called deadlock.
// Neccessary conditions for deadlock:
    : Mutual exclusion
    : No preemption
    : Hold & Wait
    : Circular wait

// Recource allocation graph:
    : we draw an edge from a recource to a process if the recource has been taken by that process.
    : we draw an edge from a process to a recource if the process has demand for that recource.
    : If there is a single instance of all recources then cyclic wait denotes deadlock and acyclic wait denotes no deadlock.
    : If there is multiple instances of recources then we have to use an algorithm(Banker's) to check deadlock.
    : the algorithm(Banker's) is: 
        : draw a table that contains how many recources allocated to a process and how many they need.
        : then maintain a state that contain how may free recources are present if any process can execute by taking some available
        recource from that state then give the recource to that process and take all the recource which was held by that process.
        : try to execute all the processes by similar fashion 
        : if all the processes get execute then there is no deadlock o/w deadlock.

// Various methods for handling deadlocks:
    : Deadlock Ingnorance(Ostrich method): we cannot affect performance of the system due to handle rare deadlocks.
    : Deadlock prevention: Try to discard one of the Neccessary condition for deadlock.
    : Deadlock Avoidance (Banker's algorithm)
    : Deadlock detection & recovery 
    
// Deadlock Avoidance algorithm(Banker's algorithm):
    : draw a table that contains how many recources allocated to a process and how many they need.
    : then maintain a state that contain how may free recources are present if any process can execute by taking some available
    recource from that state then give the recource to that process and take all the recource which was held by that process.
    : try to execute all the processes by similar fashion 
    : if all the processes get execute then there is no deadlock o/w deadlock.

// Memory management system: Efficient utilization of memory.

// Degree of Multiprogramming: Try to keep more and more program on RAM such that the efficiency of the system can increase.

// Memory management technique:
    Contiguous:
        : Fixed partitioning
        : Varibale partioning
    Non Contiguous:
        : Paging
        : Multilevel Paging
        : Inverted Paging
        : Segmentation
        : Segmented paging

// Disadvantage of fixed programming:   
    : Internal fragmentation (If we cannot use some space(the left space after aquiring space by a process in a fixed block), then it called )
    : Limit in process size
    : Limitation in degree of Multiprogramming
    : External fragmentation (If the some of some small space is greater than a process still we cannot accommodate that process due to
                            Contiguous memory allocation then this situation is called External fragmentation).

// Advantages of dynamic/variable partitioning:
    : No Internal fragmentation
    : No Limitation on degree of Multiprogramming.
    : No Limitation on process size.
// Disadvantage:
    : External fragmentation still present(but we can use undesirable method called compaction).
    : Allocation and dellocation is little complex.

// Memory allocation in variable partitioning:
    : First Fit: Allocate the process where space is enough for the process starting from top.(Simple and fast)
    : Next Fit: Same as first fit but starts the allocation from last alllocated hole.
    : Best Fit: Allocate the smallest hole that is big enough.(Internal fragmentation less but slow)
    : Worst Fit: Allocate the largest hole.(slow)

// Paging: (no External fragmentation)
    : page: The processes are divided in small fixed size pieces(page), called paging.
    : Frame: We are divide the main memory into small fixed pieces called frames.
    // size of a frame = size of a page

// Page table: Memory management unit provides the page table which maps pages to frames .
            // every process has its own page table

// we have to find the actual address(physical address(frames+offset)) of a process in main memory from address produced by cpu for a process(logical address(page+offset)).

// size of a logical address = log2(logical address space)
// size of a physical address = log2(physical address space)
// logical address = (page number) + page offset(size = log2(page size))
// physical address = (frame number) + page offset
// number of pages = pow(2,page number size)
// number of frame = pow(2,frame number size)
// number of entry in a page table = number of pages.
// Size of page table = no of pages * log2(no of frames) = no of pages * frame number size // page table map page no to frame no

// Page table entry can consists:
    :Frame number bit
    :Valid/present bit
    :protection bit
    :reference bit
    :caching bit
    :dirty/modified bit

// Multilevel paging:If the size of page table bigger than size of a frame in main memory then we have to devide 
                     our page table into pages, this method is called Multilevel paging.

// Inverted paging:There is one page table for all the processes which consists frame no as index and page no + process id as page table entry
                : searching slow

// Thrashing: The cpu utilization increases with increasing degree of Multiprogramming but drops suddenly after a fixed value of degree of Multiprogramming
                and this drop in cpu utilization is called Thrashing.
            : prevent: by increase in RAM size
                     : by slowing long term schedular

// Segmentation: Unlike paging we devide a process into segments according to user point of view such that each segment has a specific meaning of related data(block of process)
                : We uses segment table for mapping the VA to PA that consists segment no as index and Base address + size (limit) as segment table entry.
                : VA = segment no + segment offset(offset<= limit) o/w error(trap/Segmentation fault)

// Overlay: Overlay is a method in which we run a big process by taking small pieces of process in RAM one by one.

// Virtual Memory: We never try to put all the process on main memory nor we try to put all the pages of same process in main memory at same time.
    Virtual memory ensure that we can run a process which has larger size than the main memory
    and also Multiprogramming by paging.
    // We divide all processes in multiple pages and by swap in / swap out policies by various algorithm we try to reduce page fault.

// Page fault:
    If page fault occurs then cpu generates a trap on address of page fault and os takes controls from user(user lavel to os level) then after authentication os take the page from
    Virtual memory to physical memory and update the page table. Then user takes controls(os level to user level).

// if p is the probability that page fault occurs then Effective memory access time(EMAT)=p(page fault service time)+(1-p)(main memory access time)

// Translation LookAside Buffer(TLB): TLB is a cache memory which is much faster than main memory in which we put some page table entry acc to various algorithms
                                    : We try to find page table entry in TLB first if found called 'hit' o/w 'miss'.
                                    : If main memory access time x then EMAT = hit(TLB time + x ) + Miss(TLB time + 2x)

// Page replacements algorithm:
    : FIFO 
    : Optimal page replacements(replace the page which is not used in largest amount of time in future)
    : Least recently used(replace least recently used page in past)
    : most recently used(replace most recently used page in past)

// Belady's anomaly: genarally in increasing in main memory the no of page fault reduces but in case of some special reference string in fifo policy the page fault increases, called Belady anomaly.

// Hard Disk Architecture: 
    : Many platters are connected with spindle which rotate all the platters in uni direction
    : Each platters have upper and lower surface and a read write head on both surfaces
    : All read-write head of platters are connected with a Actuater arm which moves back and forth read-write head
    : platters surface has tracks and each track has sectors and sector has data

// seek time: Time taken by r/w head to reach desired track
// rotation time: Time taken for one full rotation by spindle.
// rotational latency: Time taken to reach to desired Section(half rotation time).
// transfer time: data to be transfer/ transfer rate
// transfer rate: no of surface * capacity of one track(size) * no of rotation in one second.
// disk access time: seek time + rotational time + transfer time + others.

// disk Scheduling algorithms: we try to reduce seek time
    : First come first serve(FCFS):(no starvation but low performance)
    : Sortest seek time first(SSTF):move to that track which nearest to current track. (starvation problem + additional overhead for finding nearest track)
    : SCAN algorithm: scan the whole tracks by moving one given direction from current position to end of the platters track and then in reverse direction from there.
    : LOOK algorithm: same as SCAN but the head got untill the last Neccessary track
    : Circular(C)-SCAN: same as SCAN but after the last position of the platters we simply move the head to opposite last position (without satisfying any request) and then traverse 
                        again traverse from there in same direction as before.
    : Circular(C)-LOOK: same as C-SCAN but the extreme tracks are last tracks which are in then request queue

// File System: file system helps us to store and fetch data from sector my dividing actual file in a small blocks.
                : Operation which provides file system on file:
                        Creating, Reading, Writing, Deleting, Truncating(remove only file data not attributes/metadata), Re-positioning
                : File attributes:
                        Name, Extension(type), Identifier, Location, Size, Modified/Created date, Protection/Permission, Encrytion/Compression.

// File allocation methods:
    File system breaks the file into small block and assign sector for ecch block by various allocation methods:
    : Contiguous allocation
    : Non Contiguous allocation:    
                                : Linked list allocation
                                : Indexed allocation
    : Aim:
        : Efficient disk utilization
        : Access faster

// Contiguous file allocation:
    : Advantages:
        : Easy to implement
        : Excellent read performance
    : Disadvantage:
        : Disk will become fragmented
        : Difficult to grow file

// Linked list file allocation:
    : Advantages:
        : No External fragmentation
        : File size can increase
    : Disadvantage:
        : Larger seek time
        : Difficult to random access
        : Overhead of pointers

// Indexed file allocation: each file has a index block pointed by directory and index block has index of each block of file.
    : Advantages:
        : Support direct access
        : No External fragmentation
    : Disadvantage:
        : Pointers overhead
        : Multilevel index

// Unix Inode structure:
    In Inode each block contain:
        attributes, direct block(contain pointers to data), single indirect(points to block of pointers), double indirect, triple indirect.

// Protection and Security:
    // Security voilation categories:
        : Breach of confidentiality: Unauthorized reading of data. (Encrytion technique can use)
        : Breach of intigrity: Unauthorized modification of data.
        : Breach of availability: Unauthorized destruction of data.
        : Theft of service: Unauthorized use of recources.
        : Denial of service(DOS): prevention of legitimate user.
    // Access matrix : It denotes which user have what Permission on data



