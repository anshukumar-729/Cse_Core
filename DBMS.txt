// E F Codd - father of DBMS
// Database System:
    a)Database - collection of releated data (structured(Realational model), unstructured)
    b)DBMS 

//  RDBMS - Realational Database management System

// File System vs DBMS:
    a)We can search data faslty and remotely using DBMS(searching).
    b)Do not have to know where is the location of data(attributes).
    c)Protocol exist for concurrancy in DBMS(concurrancy).
    d)DBMS provides role based security(security)
    e)DBMS stop redundancy(redundancy)

// 2-Tier and 3-Tier:
    2-Tier: Client server architecture:
        a)advantage in maintanance
        b)disadvantage in scalebality.
        c)disadvantage in security 
    3- Tier: Client, business and server architecture:
        a)advantage in security
        b)advantage in scalebality
        c)disadvantage in maintanance

// Schema:
    (logical representation of schema and collection of table)

// Three schema architecture: }-data abstraction/independence
    :View level(Normal schema)
    :logical level(conceptual schema)(E-R model Blue print)
    :Physical level(physical/Internal schema)

// Logical data independence:
    View lavel doesn't change while changing conceptual level :creating virtual table (views) for different users for making data independent 
// Physical data independence:
    conceptual level doesn't change while changing physical level

// Key:
    key is a attribute by which we can uniquely identify any two tuples(coloumn) in the table

//  collection of all attribute in the table called //candidate key(must be unique) and we choose 1 key as primary key and other known as alternative key

// primary key(Unique + not NULL): We always give primary key value to users instead of taking its entry.
    :One table has only one primary key

// Foreign key: It is a attribute or set of attributes that reference to primary key of the same table or another table
    : To maitain referential integrity
    : The table contains Foreign key called referencing table 
    : The table contains primary key called referenced table

    eg:
        Create table Course
        (
            Course_id varchar(10),
            Course_name  varchar(20),
            Roll_no references Student(Roll_no)
        );
        or 
        Alter table Course 
        ADD Constraint fk 
        foreign key(Roll_no) 
        references Student(Roll_no);
    // one table can contain more than one foreign key

// Referential integrity(same value for Database(all table)):
    Changing Referenced/ base table:(while changing referenced table is intigrity voilates)
        Insertion: No voilation
        Deletion : may do voilation : method to preventing:
                                    while making shema add (on delete Cascade)- this deletes the row from referencing table as well
                                    (on delete set NULL)- this set null as entry of foreign key bu it cannot be primary key
                                    (on delete no action)- error while deleting from base table
        Updation: same as Deletion
    Changing Referencing table: 
        Insertion : may cause voilation
        Deletion: Not cause voilation
        Updation: may cause voilation
        
// Super Key:
    A super key is a combination of all possible attribute which can uniquely identify two touples in a table.
    (super set of any candidate key is called super key)

// Entity - Relationship model(ER model):
    :Relation b/w different Entity
    :Entity is a object which has some physical existance
    :Attribute are the charactersticks of a Entity

// Types of attribute(eclipse default representation):
    :Single vs multivalued(double circle) attributes:(can have single value and multivalued respectively)
    :Simple vs Composite:(cannot divide and can divide further)
    :Stored vs Derived(dotted eclipse):(eg DOB and age)
    :Key(underline) vs Non-key:(unique and not unique)
    :Required vs Optional
    :Complex(Composite+multivalued)

// ER model to Realational model:
// Degree of Relationship (Cardinality):
    :One to One:Relationship table contains primary key of both table as foreign key and entry is one to one only
               :primary key any one in foreign keys 
               :finally we merge the two tables which have same primary key and final no of table should be 2.
    // Relationship table can have its own attributes called descriptive attributes.
    :One to Many:Relationship table contains primary key of both table as foreign key.
                :means the primary key of first table can be repeat
               :primary key is second foreign keys 
               :finally we merge the two tables which have same primary key(Relationship and 2nd) and final no of table should be 2.
    :Many to Many(M - N):Relationship table contains primary key of both table as foreign key.
                        :means the primary key of both table can be repeat.
                        :primary key will be Composite key of both foreign key.
                        :we cannot merge any two table in this case.

// Normalization:
    It is a technique to remove or reduce redundancy from a table.
    Row level duplicessy: It is already removed by primary key concept.
    Column level duplicessy: It cause problem:
                            :Intertion Anomaly(Anomaly means problem which occurs on special case)
                            :Deletion Anomaly
                            :Updation Anomaly

// Functional dependency:
    : Trivial: If Y is a subset of X then X->Y and X intersection Y !=phi 
    : Non Trivial: X->Y and X intersection Y ==phi
    // properties of Functional dependency:
        :Y is a subset of X then X->Y(reflexivity)
        :if X->Y then XZ->YZ(Augumentation)
        :if X->Y and Y->Z then X->Z(transitive)
        :if X->Y and X->Z then X->YZ(union)
        :if X->YZ then X->Y and X->Z(Decomposition)
        :if X->Y and WY->Z then WX->Z(Pseudo transitivity)
        :if X->Y and W->Z then WX->YZ(Composition)

// Closure method (Find all candidate key in a table):
            :A candidate key is a key which can determine all the attribute in a table
            eg)R(ABCD) is a Realational table
                Functional dependency {A->B, B->C, C->D}
                Closure of A = ABCD(by transitive properties) (is a candidate key)
                // here AB can determine all other attribute but it is a super key candidate key should be minimal
                // Prime attribute are those attribute which are helping in the formation of any candidate key and vise-versa for non Prime attribute
                // If any attribute not present at the right side of any Functional dependencies then for making candidate key it must be present.
    
// Normal Form:
    :First Normal Form:Table should not contain any multivalued attribute.
                    // Solution:
                        We will break Composite value into two row but table can have different primary key after.
                        We can break Composite value into two coloumn
                        Break the table into two tables
    :second Normal Form:Table must be present in first Normal form and all the non prime attribute should be fully Functional dependent on candidate key
                        :or non prime attribute must not be determine by a proper subset of candidate key(no partial dependencies)
    :Third Normal Form:Table must be present in second Normal form and table should not contain any transitive dependencies
                        :or non prime attribute must not be determine by any other non prime attribute(no transitive dependencies)
    :BCNF(Boyce Codd Normal) Form:Table must be present in Third Normal form and all attribute should be determine by the candidate or super key

// Third Normal form always ensures 'dependencies preserving Decomposition' but not BCNF
// Both Third and BCNF ensures lossless Decomposition

// lossless and lossy Decomposition:
    when we divide our Relation into two Relation and then perform natural join on both tables
    then if we choose common attribute of first table primary key or second primary key or both primary key
    then the lossless Decomposition occurs other wise lossy Decomposition occurs due to inconsistency/duplicessy in data(spuious touple)
    // Divide a table into two tables by taking care of common attribute must be a candidate key for lossless Decomposition
    // R1 intersection R2 != phi
    // R1 union R2 == R

    :Fourth Normal form:Table must be present in BCNF + has no multivalued dependencies
    :Fifth Normal form:Fourth Normal form + lossless Decomposition

// Minimal Cover:How to find? Steps:
    :Decompose all dependencies which can decomposible
    :remove all redundant Relation:  one by one removing Relation and check the dependency should not lost.
    :check if we can Decompose the left side of a dependencies (eg if(XY->Z then whether we can write X->Z or Y->Z))

// Equivalance of Functional dependency:
    if x covers y then y is a subset of x and vise versa and if both holds then x is equivalant of y.
    if x covers y then closure of (LHS of all dependencies in Y) in X must contain RHS of respective dependencies in Y.

// dependency preserving Decomposition:
    First find all possible(must have in origional Relation)non trivial dependencies in all decompose Relation then if all origional dependencies of origional Relation
    are present in union of all dependencies of decompose Relation then we call dependencies are preserve.

//Joins and Types of Joins:
    Joins are cross product of two Relation + some select statements(condition)
    :Natural join: when we want a answer which leads to equal a common attribute in two table then we use natural join
    syntax: Select * from table1,table2 where table1.common_attribute=table2.common_attribute
            : simply we write select * from table1 Natural Join table2 (common_attribute name must equal in this case)

    :Self Join: syntax: Select * from table as t1,table as t2 where condition;

    :Equi Join: We use equi join when we have to equal some other attribute unlike common attribute in natural join

    :Left Outer Join: It gives the matching rows and the rows which are in left table but not in the right table
        syntax: Select * from table1 left Outer join table2 on (condition);
    
    :Right Outer Join:Same as left Outer join

// Relational Algebra: Procedure Query Language/ Formal Query Language
    // Operators:
        Basic Operator:
        :Projection(π)
        :Selection(σ)
        :Cross Product(×)
        :Union(U)
        :Rename(ρ)
        :Set Diffrence(-)
        Derived Operator:
        :Join(⨝)
        :intersection(∩)
        :Division(/)
    // Projection Operator:π_{attribute1,attribute2}(Table);- It only show distinct row
    // Selection Operator:π_{attribute1}(σ_{condition}(Table));
    // Cross product:(Relation1 × Relation2);
    // set Diffrence:(Relation1 - Relation2); :No of Column and domain of each coloumn must be same
    // Union:(Relation1 U Relation2); :No of Column and domain of each coloumn must be same
    // Division:A(X,Y)/B(Y): It result X values for that there should be touple <X,Y> for every Y value of Relation B
                            : We uses the division Operator in (for every/ for all) Types of question
                eg) find X in A where for every Y in B there must be a Y value for every X;
                    or find X in A where for each Y for X in A contains all Y of B;
                syntax:(π_{X}(A))-(π_{X}(π_{X}(A)*π_{Y}(B)})-(π_{X,Y}(A)));

// Relational Claculus:Touple Realational Claculus and domain Relational Claculus
                        Touple Relational Claculus is non Procedure(we only have to tell what to do not bother about how to do) unlike Relational algebra
                        syntax: {t| p(t)};
                        Touple Relational Claculus and algebra have same expressive power but we have take care of unsafe expression in touple relational Claculus.

// SQL(structured query Language)(1970):
    : SQL is domain specific language
    : SQL is declarative/non Procedure language(we have to only mention what to do);

// SQL commands:
    : DDL(data definition language) commands: deals with schema(structure of the table)
        Create, Alter, Drop, Truncate, Rename
    : DML(data manipulation language) commands: data filing related commands.
        Select, Insert, Update, Delete
    : DCL( data control language) commands: Related to data prevealge
        Grant, Revoke.
    : TCL(transaction control language) commands:related to transaction of data
        Commit, Roll back, Save point
    // Constraints:
        primary key, Foreign key, Check(condition while inserting data), Unique, default, Not NULL.

// Diffrence b/w Alter and Update commands:
    :Alter is a DDL command but Update is a DML command.
    :Alter command is used to changing the structure(schema) of table while Update command is used to changing any data of the table

// Diffrence b/w Delete, Drop and Truncate commands:
    :Delete is a DML command which is used to delete any row in a table.
    :Drop is a DDL command which is used to drop whole table structure(deletes table) along with table data.
    :Truncate is a DDL command which is used to delete whole row/data from a table but table structure still exist.
    :Delete is slower than Truncate but it creates log and roll back is possible in this case.

// Group by Clause:
    Select same_att, count(*)/count(any_att) from table group by same_att
    : We use having instead of where in group by Clause.
    Select same_att from table group by same_att having condition;

// Exist and not exist: Use in corelated nested query:(inner and Outer query is corelated): inner query run for all row of Outer query and return true/false.

// corelated nested query(synchronized query):
    :It is a subquery which uses value from Outer query
    :Top Down approach (inner query run for all row of Outer query and return true/false(in case of exist).)
    eg) select * from table1 where exist (select * from table2 where table1.attribute=table2.attribute);

// Aggregate function in SQL:
    Max, Min, Count, Avg, Sum eg)Select Max(attribute) from table

eg) Difference b/w nested query, corelated subquery and joins using example:
    //nested query:  select * from table1 where attribute in (select attribute from table2);
    //corelated subquery: select * from table1 where exist (select * from table2.attribute=table2.attribute);
    //joins: select * from table1,table2 where table1.attribute=table2.attribute;

// Find Nth highest thing for a attribute in a table:
    Select * from table as t1 where n-1=(select count (distinct attribute) from table as t1 where t1.attribute<t2.attribute); 

// Regex in SQL : % works as * and _ can be any one character

// PL-SQL: Procedural SQL: It is like a program as c,c++;
    It consists three parts : Declaration(starts with declare), Excutable code(code is written b/w begin and end), Exception handling.

// Transaction: It is set of Operation used to perform a logical unit of work
                : A transaction generally represents change in Database.

// ACID properties in transaction:
    : Atomicity : Either all or none: A failed transaction cannot be resumed, it always restart(Roll back).
    : Consistency: Before the transaction starts and after the transaction completed the sum of total money must be same.
    : Isolation: In Isolation we try to convert a parallel shedule to serial shedule.
    : Durability: The data should be durable untill it update somehow.

// Transaction States:
    Begin -> Active -> Partially commited(only commit is left) -> Commited -> terminated
    Begin -> Active -> Partially commited(only commit is left) -> Failed -> Abort -> terminated
    Begin -> Active -> Failed -> Abort -> terminated

// Shedule: It is chronological execution sequence of multiple transaction.
    :Serial and Parallel shedule
    // Serial Shedule: :Transaction are done one by one in a order.
                       :Throughput(No of transaction/ time) decreases.
    // Parallel shedule: opposite of serial shedule
    // Types of problem in concurrancy(parallel shedule):
        :Dirty read/ Incommited read/ Read after write
        :Incorrect Summary: Another transaction perform its Aggregate function in the middle of one transaction.
        :Loss update(write-write problem)
        :Unrepeatable read
        :Phantom read

// Write-Read Conflict/ Dirty read problem
// Read-Write Conflict/ Unrepeatable read

// Irrecoverable shedule:(If a transaction fails then its roll back and undo all Operation due to which all the other transaction occurs in the
    middle of that transaction lossed and cannot get recover).
// Cascading shedule:(write-read) Force abort some shedule due to aborting of a shedule.(opposite- cascadeless shedule(we cannot read after any write))

// Serializability:(We check if there exist a serial shedule equivalant to given shedule)
    :Methods for checking Serializability are:
        :Conflict serializable
        :view serializable

// Conflict equivalant:
    :Conflict Pairs are:R(A)->W(A), W(A)->R(A), W(A)->W(A). else are non-conflict pairs
    :If we swap some non conflict pairs from a shedule and reach to Another(serial) shedule then the shedules are conflict equivalant.

// Conflict serializable:
    :We made a precedence graph - check conflict pairs in other transaction and draw edges in graph:
    :If we found no loop/cycle in the precedence graph then the transaction are conflict serializable -> serializable -> consistant
    :If the precedence graph consists no cycle then topological order(in degree 0) if transaction can be a serializable shedules.
    :If we found any cycle in the precedence graph then we cannot say anything

// View Serializability: if a parallel shedule is view equivalant to a serial shedule then:
                        : Read Initial value of all data item must be same
                        : Write final value of all data item must be same
                        : Both shedule must contain same W->R conflict

// Shared Exclusive Locking Protocol:
    Shared Lock(S):If transaction locked data item in Shared mode then allowed to read only.
    Exclusive Lock(X):If transaction locked data item in Exclusive mode then allowed to read and right both.
    // According to compatibility table:If Shared lock is Grant then if another Shared lock is requested then request will accept
     o/w reject in all other cases due to conflicts.
    // problems in S/X Locking:
        :May not sufficient to produce only serializable shedule.
        :May not free from recoverability
        :May not free from Roll back.
        :May not free from deadlocks.
        :May not free from starvation
    
// 2-Phase Locking (2PL):(Always ensures the Serializability)
    Growing phase:locks are aquired and no locks are released.
    Shrinking phase:locks are released and no locks are aquired.
    // disadvantages:May not free from Irrecoverability.
                    :Not free from deadlocks.
                    :Not free from starvation.
                    :Not free from cascading rollback.

// Strict 2PL: It should satisfy the basic 2PL and all Exclusive locks should hold untill commit/Abort.
             : cascadeless and Strict recoverable.
// Rigorous 2PL: It should satisfy the basic 2PL and all shared and Exclusive locks should hold untill commit/Abort.
               : cascadeless and Strict recoverable.
// Conservative 2PL:It gives all resources on a particular transaction first.
                   :All disadvantages removed.(practically not possible)

// Timestamp ordering Protocol:
    : Unique value assign to every transaction.
    : Tells the order(when they enter into System)
    : Read_TS(RTS) Latest transaction no which performed read successfully.
    : Write_TS(WTS) Latest transaction no which performed write successfully.
    // We assume that if a transaction first came then it will completes first
    // If a older Timestamp transaction wants to perform read or write after any write of elder transaction then not possible(roll back).

// Indexing: I/O cost is reduced by Indexing.(It reduced no of blocks to search) and consists a key value and a pointer for each entry.
    :Dense Indexing: Unordered data(we have to enter index for all entry of all blocks)
    :Sparse Indexing: Ordered data(we have to enter only anchor entry of each blocks)

// Types of indexes:
    :Primary
    :Clustured
    :Secondary
    // If data is sorted and data has key values(uniqueness) then we use primary index.
    // If data is sorted and data has no key values(non-unique) then we use Clustured index.
    // If data is Unordered and data has key values(uniqueness) then we use Secondary index.
    // If data is Unordered and data has no key values(non-unique) then also we use Secondary index.

// Primary Index: Its generally Sparse
                : No of entry in index table = no of blocks in hard disk
                : Average search time = log2(no of pointers in index table)+1
// Clustured index: Its also Sparse.
                  : We have to point for all unique key in table
                  : We have to use blocks hanckors which point same key to the below block(if same keys are not fit into one block)
                  : Average search time = log2(no of pointers in index table)+1+1..(for blocks hanckors) 
// Secondary index(key): Its will Dense
                       : No of entry in index table(in sorted order) = no of entry in hard disk
                       : Average search time = log2(no of pointers in index table)+1
// Secondary index(Non key): We will uses a intermediate layer which have multiple block for all unique key in hard disk and each block work as index table(dense).
                             and for each blocks we have main index table entry(sparse).
                            : We generally call it dense.

// B-Trees:(Dynamic Multilevel index) Follow binary search tree properties.
            : Blocks/Tree pointers: which points to the child of the node.
            : Key+Record/Data pointers: which points to data in the hard disk.
            : Each block can consists many block pointers and record pointers.
            // order of a b-tree is maximum no of childrens(p say) of a block/node.
            // minimum no of childrens of root node is 2 and intermediate node is ceil(p/2);
            // No of block pointers(max) = p;
            // No of record pointers(max) = p-1;
            // No of record pointers(min) = ceil(p)-1;

// Intertion in B-Tree: Use BST properties for insertion

// Difference b/w B-tree and B+-Tree:
    :B-Tree: Data is Stored in the leaf as well as internal nodes(all nodes contains BP,Key,RP)
           : searching is slower deletion is complex.
           : No redundant search key present.
           : Leaf node not linked together.
    :B+-Tree: Data is stored only in the leaf nodes.(internal nodes contains BP,Key and leafs contains RP as well but not BP except 1 BP for next leaf)
            : Searching is faster and deletion is easy.
            : redundant key may present.
            : Leafs are linked together like linked list.

// Log based recovery:
// Immediate Database Modification(Undo/Redo strategy): if a transaction starts as well as commit and if it will fails then redo o/w undo
                                                      : We store old value with new value in log file
// Deffered Database Modification(No Undo/redo strategy): if a transaction starts as well as commit and if it will fails then redo o/w nothing will done.
                                                        : We store only new value in log file
                                                    
// View in Database:    
    : virtual table(not physical existance)
    : view is the result set of a stored query
    : Read-only(We cannot modify view table) vs updatable (we can modify data in view table also change will saved in base table)views
    : Materialized view: It is a snapshot of a Database or part of a Database which aquire space.
    syntax: Create view v1 as Select * from table 
    // DDL commands are not allowed
    // advantages of view:
        :To restrict the data access.
        :To make complex query easy.
        :To provide data independence
        :To present different views of the same data

// NULL in Aggregate function:
    :All the function except count(*) ignores null value
    :Count of null value is defined as 0 and other functions returns null.

// RAID: redundant array of independent/inexpensive disk.
        : RAID 0: Data striping (Fast performance)
        : RAID 1: Mirroring (Security/Avaibility)
        : RAID 1+0: striping+Mirroring (security + performance)
        : RAID 3: We store data into peices in different disks and one disk(parity disk) contains parity of all block parallel to it.
        : RAID 5: RAID 5 distributes the parity disk in all disks
        : RAID 6: we calculate two parities for all parallel bits
    
// Various object in Database:
    :Table: Basic unit od=f storage composed of rows and coloumn.
    :View: Logical represent subset of data from one or more table
    :Sequence: Generate numeric values(automatically)
    :Index: Improve of the data retrieval queries.
    :Synonyms: Gives alternative names to the objects.



